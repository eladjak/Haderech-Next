[
  {
    "filePath": "C:\\Users\\eladj\\Documents\\haderech-next\\lib\\services\\simulator.ts",
    "messages": [
      {
        "ruleId": "import/order",
        "severity": 1,
        "message": "There should be at least one empty line between import groups",
        "line": 3,
        "column": 1,
        "nodeType": "ImportDeclaration",
        "endLine": 3,
        "endColumn": 37,
        "fix": { "range": [123, 123], "text": "\n" }
      }
    ],
    "suppressedMessages": [],
    "errorCount": 0,
    "fatalErrorCount": 0,
    "warningCount": 1,
    "fixableErrorCount": 0,
    "fixableWarningCount": 1,
    "source": "import { createClient } from \"@supabase/supabase-js\";\nimport { OpenAI } from \"openai\";\nimport { v4 as uuidv4 } from \"uuid\";\nimport { _FEEDBACK_CRITERIA, _SCENARIO_TYPES } from \"@/constants/simulator\";\nimport { config } from \"@/lib/config\";\nimport type {\n  FeedbackDetails,\n  FeedbackMetrics,\n  Message,\n  _MessageFeedback,\n  SimulatorScenario,\n  SimulatorSession,\n  SimulatorState,\n} from \"@/types/simulator\";\n\n// Use environment variables from config\nconst supabaseUrl = config.supabaseUrl;\nconst supabaseKey = process.env[\"SUPABASE_SERVICE_ROLE_KEY\"];\n\nif (!supabaseUrl || !supabaseKey) {\n  throw new Error(\"Missing required environment variables\");\n}\n\nconst supabase = createClient(supabaseUrl, supabaseKey);\nconst _openai = new OpenAI({ apiKey: config.openaiApiKey });\n\n// Default values for feedback components\nconst DEFAULT_COMMENTS = \"No special comments\";\nconst DEFAULT_SUGGESTIONS = [\"No improvement suggestions\"];\nconst DEFAULT_TIPS = [\"No additional tips\"];\nconst DEFAULT_STRENGTHS = [\"No special strengths\"];\nconst DEFAULT_IMPROVEMENTS = [\"No improvement points\"];\n\n/**\n * Start a new simulation session with the given scenario\n * @param scenario The scenario to simulate\n * @param userId The ID of the user starting the simulation\n * @returns A new simulation session\n */\nexport async function startSimulation(\n  scenario: SimulatorScenario,\n  userId: string\n): Promise<SimulatorSession> {\n  const timestamp = new Date().toISOString();\n  const initialMessage: Message = {\n    id: uuidv4(),\n    role: \"assistant\",\n    content: scenario.initial_message,\n    timestamp,\n    created_at: timestamp,\n    updated_at: timestamp,\n    sender: {\n      id: uuidv4(),\n      role: \"assistant\",\n      name: \"System\",\n    },\n  };\n\n  const state: SimulatorState = {\n    id: uuidv4(),\n    user_id: userId,\n    scenario_id: scenario.id,\n    scenario,\n    status: \"idle\",\n    messages: [initialMessage],\n    state: \"initial\",\n    created_at: timestamp,\n    updated_at: timestamp,\n  };\n\n  const session: SimulatorSession = {\n    id: uuidv4(),\n    user_id: userId,\n    scenario_id: scenario.id,\n    scenario,\n    status: \"idle\",\n    state,\n    messages: [initialMessage],\n    created_at: timestamp,\n    updated_at: timestamp,\n  };\n\n  await saveSimulationState(session);\n  return session;\n}\n\n/**\n * Generate feedback for a set of messages in a simulation\n * @param messages The messages to analyze for feedback\n * @returns Detailed feedback with metrics and suggestions\n */\nasync function _generateFeedback(\n  messages: readonly Message[]\n): Promise<FeedbackDetails> {\n  const metrics: FeedbackMetrics = {\n    empathy: 0,\n    clarity: 0,\n    effectiveness: 0,\n    appropriateness: 0,\n    professionalism: 0,\n    problem_solving: 0,\n    overall: 0,\n  };\n\n  // Analyze messages and calculate scores\n  for (const message of messages) {\n    if (message.role === \"user\") {\n      metrics.empathy = calculateEmpathyScore(message.content);\n      metrics.clarity = calculateClarityScore(message.content);\n      metrics.effectiveness = calculateEffectivenessScore(message.content);\n      metrics.appropriateness = calculateAppropriatenessScore(message.content);\n      metrics.professionalism = calculateProfessionalismScore(message.content);\n      metrics.problem_solving = calculateProblemSolvingScore(message.content);\n    }\n  }\n\n  const score = calculateMetricsScore(metrics);\n  metrics.overall = score;\n\n  return {\n    metrics,\n    score,\n    strengths: [...DEFAULT_STRENGTHS],\n    improvements: [...DEFAULT_IMPROVEMENTS],\n    tips: [...DEFAULT_TIPS],\n    comments: DEFAULT_COMMENTS,\n    suggestions: [...DEFAULT_SUGGESTIONS],\n    overallProgress: {\n      score,\n      level: \"Beginner\",\n      nextLevel: \"Advanced\",\n      requiredScore: 80,\n    },\n  };\n}\n\nfunction calculateScore(content: string, criteria: string[]): number {\n  let score = 0;\n  criteria.forEach((criterion) => {\n    if (content.toLowerCase().includes(criterion.toLowerCase())) {\n      score += 20;\n    }\n  });\n  return Math.min(100, score);\n}\n\nfunction calculateEmpathyScore(content: string): number {\n  const empathyCriteria = [\n    \"╫נ╫á╫ש ╫₧╫ס╫ש╫ƒ\",\n    \"╫נ╫á╫ש ╫₧╫¿╫ע╫ש╫⌐\",\n    \"╫נ╫á╫ש ╫⌐╫ץ╫₧╫ó\",\n    \"╫צ╫פ ╫á╫⌐╫₧╫ó\",\n    \"╫נ╫á╫ש ╫₧╫ª╫ר╫ó╫¿\",\n  ];\n  return calculateScore(content, empathyCriteria);\n}\n\nfunction calculateClarityScore(content: string): number {\n  const clarityCriteria = [\n    \"╫פ╫נ╫¥ ╫צ╫פ ╫ס╫¿╫ץ╫¿\",\n    \"╫נ╫á╫ש ╫נ╫í╫ס╫ש╫¿\",\n    \"╫£╫ף╫ץ╫ע╫₧╫פ\",\n    \"╫¢╫£╫ץ╫₧╫¿\",\n    \"╫ס╫₧╫ש╫£╫ש╫¥ ╫נ╫ק╫¿╫ץ╫¬\",\n  ];\n  return calculateScore(content, clarityCriteria);\n}\n\nfunction calculateEffectivenessScore(content: string): number {\n  const effectivenessCriteria = [\n    \"╫נ╫á╫ש ╫₧╫ª╫ש╫ó\",\n    \"╫נ╫ñ╫⌐╫¿ ╫£╫á╫í╫ץ╫¬\",\n    \"╫פ╫ñ╫¬╫¿╫ץ╫ƒ\",\n    \"╫פ╫ף╫¿╫ת ╫פ╫ר╫ץ╫ס╫פ\",\n    \"╫ש╫ó╫צ╫ץ╫¿ ╫£╫ת\",\n  ];\n  return calculateScore(content, effectivenessCriteria);\n}\n\nfunction calculateAppropriatenessScore(content: string): number {\n  const appropriatenessCriteria = [\n    \"╫ס╫פ╫¬╫נ╫¥ ╫£\",\n    \"╫₧╫¬╫נ╫ש╫¥ ╫£\",\n    \"╫ס╫פ╫º╫⌐╫¿\",\n    \"╫£╫ñ╫ש ╫פ╫₧╫ª╫ס\",\n    \"╫ס╫⌐╫£╫ס ╫צ╫פ\",\n  ];\n  return calculateScore(content, appropriatenessCriteria);\n}\n\nfunction calculateProfessionalismScore(content: string): number {\n  const professionalismCriteria = [\"╫₧╫º╫ª╫ץ╫ó╫ש\", \"╫₧╫ש╫ץ╫₧╫ƒ\", \"╫₧╫á╫ץ╫í╫פ\", \"╫₧╫ץ╫₧╫ק╫פ\", \"╫ס╫º╫ש╫נ\"];\n  return calculateScore(content, professionalismCriteria);\n}\n\nfunction calculateProblemSolvingScore(content: string): number {\n  const problemSolvingCriteria = [\"╫ñ╫¬╫¿╫ץ╫ƒ\", \"╫ף╫¿╫ת\", \"╫נ╫ñ╫⌐╫¿╫ץ╫¬\", \"╫ק╫£╫ץ╫ñ╫פ\", \"╫פ╫ª╫ó╫פ\"];\n  return calculateScore(content, problemSolvingCriteria);\n}\n\nfunction calculateMetricsScore(metrics: FeedbackMetrics): number {\n  return Math.round(\n    (metrics.empathy +\n      metrics.clarity +\n      metrics.effectiveness +\n      metrics.appropriateness +\n      metrics.professionalism +\n      metrics.problem_solving) /\n      6\n  );\n}\n\nasync function saveSimulationState(session: SimulatorSession): Promise<void> {\n  const { error } = await supabase\n    .from(\"simulator_sessions\")\n    .update({\n      messages: session.messages,\n      feedback: session.feedback,\n      updated_at: session.updated_at,\n    })\n    .eq(\"id\", session.id);\n\n  if (error) {\n    console.error(\"Error updating session:\", error);\n    throw new Error(\"Failed to update session\");\n  }\n}\n\nexport function evaluateEmpathy(_content: string): number {\n  return Math.random() * 10;\n}\n\nexport function evaluateClarity(_content: string): number {\n  return Math.random() * 10;\n}\n\nexport function evaluateEffectiveness(_content: string): number {\n  return Math.random() * 10;\n}\n\nexport function evaluateAppropriateness(_content: string): number {\n  return Math.random() * 10;\n}\n\nexport function evaluateProfessionalism(_content: string): number {\n  return Math.random() * 10;\n}\n\nexport function evaluateProblemSolving(_content: string): number {\n  return Math.random() * 10;\n}\n",
    "usedDeprecatedRules": []
  }
]
